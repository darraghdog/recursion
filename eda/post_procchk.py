#usage python post_processing.py ./submit_17.txt ./submit_17_submit_postprocess.csv

import argparse
import os
import torch
import tqdm
import numpy as np
import pandas as pd


def _get_train_groups():
    '''
    # We store the groups in the script so we do not need to reload train, but below is how we get them
    traindf = pd.read_csv('train.csv')
    plate_groups = np.zeros((1108,4), int)
    for sirna in range(1108):
        grp = traindf.loc[traindf.sirna==sirna,:].plate.value_counts().index.values
        assert len(grp) == 3
        plate_groups[sirna,0:3] = grp
        plate_groups[sirna,3] = 10 - grp.sum()
    '''
    grp1 = [4,1,2,1,3,1,1,2,1,4,1,2,4,4,4,4,4,4,4,2,2,3,2,4,3,2,1,2,2,3,4,4,3,1,3,3,4,4,3,3,1,2,2,2,2,4,1,2,1,3,4,3,2,3,4,1,1,2,4,1,2,2,3,2,2,3,2,4,4,4,1,4,2,4,1,2,3,1,2,4,1,2,4,2,3,4,3,2,1,1,3,1,2,2,1,2,3,4,3,3,2,2,1,4,4,1,4,4,2,1,4,2,1,1,3,3,4,2,2,3,3,3,3,3,1,3,1,3,4,3,2,2,2,1,3,3,1,4,2,4,4,4,3,4,1,3,2,1,3,2,4,3,4,2,4,1,4,1,1,3,2,4,1,3,2,2,2,3,3,2,3,3,1,3,3,2,4,1,2,4,3,1,2,3,3,3,3,4,1,2,3,3,1,4,2,1,2,3,3,4,4,4,4,1,4,4,2,2,4,4,3,1,1,4,3,3,2,1,2,2,4,1,1,4,1,2,4,4,2,3,4,4,2,2,3,4,2,3,1,1,4,4,1,4,3,2,3,4,3,4,3,4,3,1,1,3,1,2,1,3,4,4,2,2,4,3,1,3,1,2,4,3,1,4,1,4,1,1,3,3,4,1,1,3,2,2,4,1,4,3,1,3,4,1,4,1,1,4,4,2,3,1,1,2,4,2,4,3,1,1,3,3,1,1,3,2,4,2,4,3,1,4,3,4,1,4,3,2,4,2,2,4,4,2,2,3,2,3,3,1,1,1,2,4,4,1,1,3,1,2,1,2,1,2,4,1,4,2,4,3,1,1,3,3,2,3,1,4,3,3,4,1,1,1,4,3,2,3,4,1,3,2,3,2,2,1,4,3,1,1,2,1,1,2,3,1,3,1,1,1,1,3,3,4,2,3,4,2,2,2,3,1,2,1,2,1,4,1,4,4,4,2,3,2,2,2,4,4,2,2,4,1,3,4,2,3,1,3,3,1,4,4,1,3,3,1,3,2,3,3,1,4,2,3,2,4,1,2,4,1,1,2,2,3,3,3,2,2,4,3,4,1,4,2,4,2,4,3,1,2,3,1,1,2,3,3,1,3,4,1,3,3,2,4,3,2,4,1,4,2,1,3,2,1,3,1,1,2,1,4,3,2,3,1,1,3,3,2,4,4,3,2,4,1,4,3,4,3,4,2,3,4,1,3,4,2,2,1,1,2,4,1,2,1,2,3,3,1,3,1,2,3,1,2,3,1,1,1,2,1,4,4,2,2,3,1,1,1,4,2,3,2,1,4,4,4,1,1,3,2,2,1,1,3,2,1,3,4,1,4,3,4,4,3,4,3,4,2,1,3,2,2,4,3,1,1,1,1,3,4,4,1,4,1,3,2,3,3,1,4,1,4,1,2,1,3,1,3,4,3,4,4,3,3,4,4,3,3,4,2,2,4,2,3,3,4,3,1,3,3,2,2,3,1,2,1,4,1,3,2,1,2,2,4,3,3,3,2,4,2,1,3,3,1,3,4,1,3,3,3,4,1,2,2,4,2,3,1,4,1,3,3,1,4,2,1,4,2,4,1,1,2,4,1,1,1,2,3,1,2,4,4,4,3,2,1,3,2,3,3,4,2,2,2,2,4,2,3,4,2,2,2,2,2,1,2,2,4,3,2,3,4,1,1,1,1,4,2,3,3,1,2,2,2,2,3,4,1,4,3,1,2,1,3,1,1,2,4,3,3,1,4,4,4,3,1,2,3,4,2,4,2,3,2,1,4,1,2,2,2,2,1,4,1,4,3,3,1,1,4,3,2,3,4,2,3,1,3,3,3,1,1,4,2,4,3,3,4,3,3,3,3,4,4,4,1,2,2,1,3,2,1,4,4,3,4,4,2,1,4,1,4,3,4,2,1,4,1,3,2,4,2,2,1,4,4,2,2,3,2,3,3,4,3,3,2,3,2,1,3,1,2,4,3,2,1,2,1,4,2,4,1,4,1,1,4,3,2,3,1,1,1,4,2,1,3,2,1,2,4,1,3,2,2,4,2,4,1,3,2,1,4,4,2,1,2,3,2,2,3,2,1,3,2,4,4,3,2,4,4,4,4,2,3,2,4,3,3,1,1,3,2,3,3,3,1,2,3,4,4,1,2,2,4,4,3,2,2,4,1,1,3,1,3,4,2,2,2,2,3,3,4,1,4,1,2,4,3,1,4,4,1,1,1,1,4,1,1,2,3,3,2,3,4,4,3,2,4,4,3,3,4,2,2,4,4,1,3,1,4,4,4,3,1,3,1,2,2,3,2,1,4,4,1,2,1,4,1,1,3,2,1,2,2,3,2,4,4,4,1,2,1,1,2,2,4,2,2,4,2,4,3,2,3,4,4,1,3,2,3,1,4,1,2,2,1,1,1,3,4,2,3,4,4,3,4,1,2,2,3,2,4,4,2,1,3,3,3,2,1,2,3,2,3,4,4,1,4,2,3,1,1,1,4,1,3,1,4]
    grp2 = [2,3,4,3,1,3,3,4,3,2,3,4,2,2,2,2,2,2,2,4,4,1,4,2,1,4,3,4,4,1,2,2,1,3,1,1,2,2,1,1,3,4,4,4,4,2,3,4,3,1,2,1,4,1,2,3,3,4,2,3,4,4,1,4,4,1,4,2,2,2,3,2,4,2,3,4,1,3,4,2,3,4,2,4,1,2,1,4,3,3,1,3,4,4,3,4,1,2,1,1,4,4,3,2,2,3,2,2,4,3,2,4,3,3,1,1,2,4,4,1,1,1,1,1,3,1,3,1,2,1,4,4,4,3,1,1,3,2,4,2,2,2,1,2,3,1,4,3,1,4,2,1,2,4,2,3,2,3,3,1,4,2,3,1,4,4,4,1,1,4,1,1,3,1,1,4,2,3,4,2,1,3,4,1,1,1,1,2,3,4,1,1,3,2,4,3,4,1,1,2,2,2,2,3,2,2,4,4,2,2,1,3,3,2,1,1,4,3,4,4,2,3,3,2,3,4,2,2,4,1,2,2,4,4,1,2,4,1,3,3,2,2,3,2,1,4,1,2,1,2,1,2,1,3,3,1,3,4,3,1,2,2,4,4,2,1,3,1,3,4,2,1,3,2,3,2,3,3,1,1,2,3,3,1,4,4,2,3,2,1,3,1,2,3,2,3,3,2,2,4,1,3,3,4,2,4,2,1,3,3,1,1,3,3,1,4,2,4,2,1,3,2,1,2,3,2,1,4,2,4,4,2,2,4,4,1,4,1,1,3,3,3,4,2,2,3,3,1,3,4,3,4,3,4,2,3,2,4,2,1,3,3,1,1,4,1,3,2,1,1,2,3,3,3,2,1,4,1,2,3,1,4,1,4,4,3,2,1,3,3,4,3,3,4,1,3,1,3,3,3,3,1,1,2,4,1,2,4,4,4,1,3,4,3,4,3,2,3,2,2,2,4,1,4,4,4,2,2,4,4,2,3,1,2,4,1,3,1,1,3,2,2,3,1,1,3,1,4,1,1,3,2,4,1,4,2,3,4,2,3,3,4,4,1,1,1,4,4,2,1,2,3,2,4,2,4,2,1,3,4,1,3,3,4,1,1,3,1,2,3,1,1,4,2,1,4,2,3,2,4,3,1,4,3,1,3,3,4,3,2,1,4,1,3,3,1,1,4,2,2,1,4,2,3,2,1,2,1,2,4,1,2,3,1,2,4,4,3,3,4,2,3,4,3,4,1,1,3,1,3,4,1,3,4,1,3,3,3,4,3,2,2,4,4,1,3,3,3,2,4,1,4,3,2,2,2,3,3,1,4,4,3,3,1,4,3,1,2,3,2,1,2,2,1,2,1,2,4,3,1,4,4,2,1,3,3,3,3,1,2,2,3,2,3,1,4,1,1,3,2,3,2,3,4,3,1,3,1,2,1,2,2,1,1,2,2,1,1,2,4,4,2,4,1,1,2,1,3,1,1,4,4,1,3,4,3,2,3,1,4,3,4,4,2,1,1,1,4,2,4,3,1,1,3,1,2,3,1,1,1,2,3,4,4,2,4,1,3,2,3,1,1,3,2,4,3,2,4,2,3,3,4,2,3,3,3,4,1,3,4,2,2,2,1,4,3,1,4,1,1,2,4,4,4,4,2,4,1,2,4,4,4,4,4,3,4,4,2,1,4,1,2,3,3,3,3,2,4,1,1,3,4,4,4,4,1,2,3,2,1,3,4,3,1,3,3,4,2,1,1,3,2,2,2,1,3,4,1,2,4,2,4,1,4,3,2,3,4,4,4,4,3,2,3,2,1,1,3,3,2,1,4,1,2,4,1,3,1,1,1,3,3,2,4,2,1,1,2,1,1,1,1,2,2,2,3,4,4,3,1,4,3,2,2,1,2,2,4,3,2,3,2,1,2,4,3,2,3,1,4,2,4,4,3,2,2,4,4,1,4,1,1,2,1,1,4,1,4,3,1,3,4,2,1,4,3,4,3,2,4,2,3,2,3,3,2,1,4,1,3,3,3,2,4,3,1,4,3,4,2,3,1,4,4,2,4,2,3,1,4,3,2,2,4,3,4,1,4,4,1,4,3,1,4,2,2,1,4,2,2,2,2,4,1,4,2,1,1,3,3,1,4,1,1,1,3,4,1,2,2,3,4,4,2,2,1,4,4,2,3,3,1,3,1,2,4,4,4,4,1,1,2,3,2,3,4,2,1,3,2,2,3,3,3,3,2,3,3,4,1,1,4,1,2,2,1,4,2,2,1,1,2,4,4,2,2,3,1,3,2,2,2,1,3,1,3,4,4,1,4,3,2,2,3,4,3,2,3,3,1,4,3,4,4,1,4,2,2,2,3,4,3,3,4,4,2,4,4,2,4,2,1,4,1,2,2,3,1,4,1,3,2,3,4,4,3,3,3,1,2,4,1,2,2,1,2,3,4,4,1,4,2,2,4,3,1,1,1,4,3,4,1,4,1,2,2,3,2,4,1,3,3,3,2,3,1,3,2]
    grp3 = [3,4,1,4,2,4,4,1,4,3,4,1,3,3,3,3,3,3,3,1,1,2,1,3,2,1,4,1,1,2,3,3,2,4,2,2,3,3,2,2,4,1,1,1,1,3,4,1,4,2,3,2,1,2,3,4,4,1,3,4,1,1,2,1,1,2,1,3,3,3,4,3,1,3,4,1,2,4,1,3,4,1,3,1,2,3,2,1,4,4,2,4,1,1,4,1,2,3,2,2,1,1,4,3,3,4,3,3,1,4,3,1,4,4,2,2,3,1,1,2,2,2,2,2,4,2,4,2,3,2,1,1,1,4,2,2,4,3,1,3,3,3,2,3,4,2,1,4,2,1,3,2,3,1,3,4,3,4,4,2,1,3,4,2,1,1,1,2,2,1,2,2,4,2,2,1,3,4,1,3,2,4,1,2,2,2,2,3,4,1,2,2,4,3,1,4,1,2,2,3,3,3,3,4,3,3,1,1,3,3,2,4,4,3,2,2,1,4,1,1,3,4,4,3,4,1,3,3,1,2,3,3,1,1,2,3,1,2,4,4,3,3,4,3,2,1,2,3,2,3,2,3,2,4,4,2,4,1,4,2,3,3,1,1,3,2,4,2,4,1,3,2,4,3,4,3,4,4,2,2,3,4,4,2,1,1,3,4,3,2,4,2,3,4,3,4,4,3,3,1,2,4,4,1,3,1,3,2,4,4,2,2,4,4,2,1,3,1,3,2,4,3,2,3,4,3,2,1,3,1,1,3,3,1,1,2,1,2,2,4,4,4,1,3,3,4,4,2,4,1,4,1,4,1,3,4,3,1,3,2,4,4,2,2,1,2,4,3,2,2,3,4,4,4,3,2,1,2,3,4,2,1,2,1,1,4,3,2,4,4,1,4,4,1,2,4,2,4,4,4,4,2,2,3,1,2,3,1,1,1,2,4,1,4,1,4,3,4,3,3,3,1,2,1,1,1,3,3,1,1,3,4,2,3,1,2,4,2,2,4,3,3,4,2,2,4,2,1,2,2,4,3,1,2,1,3,4,1,3,4,4,1,1,2,2,2,1,1,3,2,3,4,3,1,3,1,3,2,4,1,2,4,4,1,2,2,4,2,3,4,2,2,1,3,2,1,3,4,3,1,4,2,1,4,2,4,4,1,4,3,2,1,2,4,4,2,2,1,3,3,2,1,3,4,3,2,3,2,3,1,2,3,4,2,3,1,1,4,4,1,3,4,1,4,1,2,2,4,2,4,1,2,4,1,2,4,4,4,1,4,3,3,1,1,2,4,4,4,3,1,2,1,4,3,3,3,4,4,2,1,1,4,4,2,1,4,2,3,4,3,2,3,3,2,3,2,3,1,4,2,1,1,3,2,4,4,4,4,2,3,3,4,3,4,2,1,2,2,4,3,4,3,4,1,4,2,4,2,3,2,3,3,2,2,3,3,2,2,3,1,1,3,1,2,2,3,2,4,2,2,1,1,2,4,1,4,3,4,2,1,4,1,1,3,2,2,2,1,3,1,4,2,2,4,2,3,4,2,2,2,3,4,1,1,3,1,2,4,3,4,2,2,4,3,1,4,3,1,3,4,4,1,3,4,4,4,1,2,4,1,3,3,3,2,1,4,2,1,2,2,3,1,1,1,1,3,1,2,3,1,1,1,1,1,4,1,1,3,2,1,2,3,4,4,4,4,3,1,2,2,4,1,1,1,1,2,3,4,3,2,4,1,4,2,4,4,1,3,2,2,4,3,3,3,2,4,1,2,3,1,3,1,2,1,4,3,4,1,1,1,1,4,3,4,3,2,2,4,4,3,2,1,2,3,1,2,4,2,2,2,4,4,3,1,3,2,2,3,2,2,2,2,3,3,3,4,1,1,4,2,1,4,3,3,2,3,3,1,4,3,4,3,2,3,1,4,3,4,2,1,3,1,1,4,3,3,1,1,2,1,2,2,3,2,2,1,2,1,4,2,4,1,3,2,1,4,1,4,3,1,3,4,3,4,4,3,2,1,2,4,4,4,3,1,4,2,1,4,1,3,4,2,1,1,3,1,3,4,2,1,4,3,3,1,4,1,2,1,1,2,1,4,2,1,3,3,2,1,3,3,3,3,1,2,1,3,2,2,4,4,2,1,2,2,2,4,1,2,3,3,4,1,1,3,3,2,1,1,3,4,4,2,4,2,3,1,1,1,1,2,2,3,4,3,4,1,3,2,4,3,3,4,4,4,4,3,4,4,1,2,2,1,2,3,3,2,1,3,3,2,2,3,1,1,3,3,4,2,4,3,3,3,2,4,2,4,1,1,2,1,4,3,3,4,1,4,3,4,4,2,1,4,1,1,2,1,3,3,3,4,1,4,4,1,1,3,1,1,3,1,3,2,1,2,3,3,4,2,1,2,4,3,4,1,1,4,4,4,2,3,1,2,3,3,2,3,4,1,1,2,1,3,3,1,4,2,2,2,1,4,1,2,1,2,3,3,4,3,1,2,4,4,4,3,4,2,4,3]
    grp4 = [1,2,3,2,4,2,2,3,2,1,2,3,1,1,1,1,1,1,1,3,3,4,3,1,4,3,2,3,3,4,1,1,4,2,4,4,1,1,4,4,2,3,3,3,3,1,2,3,2,4,1,4,3,4,1,2,2,3,1,2,3,3,4,3,3,4,3,1,1,1,2,1,3,1,2,3,4,2,3,1,2,3,1,3,4,1,4,3,2,2,4,2,3,3,2,3,4,1,4,4,3,3,2,1,1,2,1,1,3,2,1,3,2,2,4,4,1,3,3,4,4,4,4,4,2,4,2,4,1,4,3,3,3,2,4,4,2,1,3,1,1,1,4,1,2,4,3,2,4,3,1,4,1,3,1,2,1,2,2,4,3,1,2,4,3,3,3,4,4,3,4,4,2,4,4,3,1,2,3,1,4,2,3,4,4,4,4,1,2,3,4,4,2,1,3,2,3,4,4,1,1,1,1,2,1,1,3,3,1,1,4,2,2,1,4,4,3,2,3,3,1,2,2,1,2,3,1,1,3,4,1,1,3,3,4,1,3,4,2,2,1,1,2,1,4,3,4,1,4,1,4,1,4,2,2,4,2,3,2,4,1,1,3,3,1,4,2,4,2,3,1,4,2,1,2,1,2,2,4,4,1,2,2,4,3,3,1,2,1,4,2,4,1,2,1,2,2,1,1,3,4,2,2,3,1,3,1,4,2,2,4,4,2,2,4,3,1,3,1,4,2,1,4,1,2,1,4,3,1,3,3,1,1,3,3,4,3,4,4,2,2,2,3,1,1,2,2,4,2,3,2,3,2,3,1,2,1,3,1,4,2,2,4,4,3,4,2,1,4,4,1,2,2,2,1,4,3,4,1,2,4,3,4,3,3,2,1,4,2,2,3,2,2,3,4,2,4,2,2,2,2,4,4,1,3,4,1,3,3,3,4,2,3,2,3,2,1,2,1,1,1,3,4,3,3,3,1,1,3,3,1,2,4,1,3,4,2,4,4,2,1,1,2,4,4,2,4,3,4,4,2,1,3,4,3,1,2,3,1,2,2,3,3,4,4,4,3,3,1,4,1,2,1,3,1,3,1,4,2,3,4,2,2,3,4,4,2,4,1,2,4,4,3,1,4,3,1,2,1,3,2,4,3,2,4,2,2,3,2,1,4,3,4,2,2,4,4,3,1,1,4,3,1,2,1,4,1,4,1,3,4,1,2,4,1,3,3,2,2,3,1,2,3,2,3,4,4,2,4,2,3,4,2,3,4,2,2,2,3,2,1,1,3,3,4,2,2,2,1,3,4,3,2,1,1,1,2,2,4,3,3,2,2,4,3,2,4,1,2,1,4,1,1,4,1,4,1,3,2,4,3,3,1,4,2,2,2,2,4,1,1,2,1,2,4,3,4,4,2,1,2,1,2,3,2,4,2,4,1,4,1,1,4,4,1,1,4,4,1,3,3,1,3,4,4,1,4,2,4,4,3,3,4,2,3,2,1,2,4,3,2,3,3,1,4,4,4,3,1,3,2,4,4,2,4,1,2,4,4,4,1,2,3,3,1,3,4,2,1,2,4,4,2,1,3,2,1,3,1,2,2,3,1,2,2,2,3,4,2,3,1,1,1,4,3,2,4,3,4,4,1,3,3,3,3,1,3,4,1,3,3,3,3,3,2,3,3,1,4,3,4,1,2,2,2,2,1,3,4,4,2,3,3,3,3,4,1,2,1,4,2,3,2,4,2,2,3,1,4,4,2,1,1,1,4,2,3,4,1,3,1,3,4,3,2,1,2,3,3,3,3,2,1,2,1,4,4,2,2,1,4,3,4,1,3,4,2,4,4,4,2,2,1,3,1,4,4,1,4,4,4,4,1,1,1,2,3,3,2,4,3,2,1,1,4,1,1,3,2,1,2,1,4,1,3,2,1,2,4,3,1,3,3,2,1,1,3,3,4,3,4,4,1,4,4,3,4,3,2,4,2,3,1,4,3,2,3,2,1,3,1,2,1,2,2,1,4,3,4,2,2,2,1,3,2,4,3,2,3,1,2,4,3,3,1,3,1,2,4,3,2,1,1,3,2,3,4,3,3,4,3,2,4,3,1,1,4,3,1,1,1,1,3,4,3,1,4,4,2,2,4,3,4,4,4,2,3,4,1,1,2,3,3,1,1,4,3,3,1,2,2,4,2,4,1,3,3,3,3,4,4,1,2,1,2,3,1,4,2,1,1,2,2,2,2,1,2,2,3,4,4,3,4,1,1,4,3,1,1,4,4,1,3,3,1,1,2,4,2,1,1,1,4,2,4,2,3,3,4,3,2,1,1,2,3,2,1,2,2,4,3,2,3,3,4,3,1,1,1,2,3,2,2,3,3,1,3,3,1,3,1,4,3,4,1,1,2,4,3,4,2,1,2,3,3,2,2,2,4,1,3,4,1,1,4,1,2,3,3,4,3,1,1,3,2,4,4,4,3,2,3,4,3,4,1,1,2,1,3,4,2,2,2,1,2,4,2,1]
    plate_groups = np.array([grp1, grp2, grp3, grp4]).T
    return plate_groups

def _get_predicts(predicts, coefficients):
    return torch.einsum("ij,j->ij", (predicts, coefficients))


def _get_labels_distribution(predicts, coefficients):
    predicts = _get_predicts(predicts, coefficients)
    labels = predicts.argmax(dim=-1)
    counter = torch.bincount(labels, minlength=predicts.shape[1])
    return counter


def _compute_score_with_coefficients(predicts, coefficients):
    counter = _get_labels_distribution(predicts, coefficients).float()
    counter = counter * 100 / len(predicts)
    #max_scores = torch.ones(len(coefficients)).cuda().float() * 100 / len(coefficients)
    max_scores = torch.ones(len(coefficients)).float() * 100 / len(coefficients)
    result, _ = torch.min(torch.cat([counter.unsqueeze(0), max_scores.unsqueeze(0)], dim=0), dim=0)

    return float(result.sum().cpu())


def _find_best_coefficients(predicts, coefficients, alpha=0.001, iterations=100):
    best_coefficients = coefficients.clone()
    best_score = _compute_score_with_coefficients(predicts, coefficients)

    for _ in tqdm.trange(iterations):
        counter = _get_labels_distribution(predicts, coefficients)
        label = int(torch.argmax(counter).cpu())
        coefficients[label] -= alpha
        score = _compute_score_with_coefficients(predicts, coefficients)
        if score > best_score:
            best_score = score
            best_coefficients = coefficients.clone()

    return best_coefficients


def main():
    
    parser = argparse.ArgumentParser()
    parser.add_argument("input_path")
    parser.add_argument("output_path")
    parser.add_argument("--start_alpha", type=float, default=0.01)
    parser.add_argument("--min_alpha", type=float, default=0.0001)

    args = parser.parse_args()
    
    #load to pandas df and convert to npy
    df = pd.read_csv(args.input_path)
    inp = '/Users/dhanley2/Documents/Personal/recursion/sub/weights/v31/probs_v31_512_fold0.csv.gzip'
    outp = '/Users/dhanley2/Documents/Personal/recursion/data/train.csv'
    df = pd.read_csv(inp, compression='gzip')
    traindf = pd.read_csv(outp)
    df['sirna'] = traindf.set_index('id_code').loc[df['id_code'].tolist()]['sirna'].values
    
    
    df[['expt','tray', 'cell']] = df['id_code'].str.split('_',expand=True)
    unique_expt = np.unique(df['expt'])
    
    # Process the train leak
    plate_groups = _get_train_groups()
    
    # Assign groups to plates
    all_test_exp = df.expt.unique()
    group_plate_probs = np.zeros((len(all_test_exp),4))
    for idx in range(len(all_test_exp)):
        preds = df.loc[df.expt == all_test_exp[idx]].values[:,:1108].argmax(1)
        pp_mult = np.zeros((len(preds),1108))
        pp_mult[range(len(preds)),preds] = 1
        sub_test = df.loc[df.expt == all_test_exp[idx],:]
        assert len(pp_mult) == len(sub_test)
        for j in range(4):
            mask = np.repeat(plate_groups[np.newaxis, :, j], len(pp_mult), axis=0) == \
                   np.repeat(sub_test.tray.values[:, np.newaxis].astype(np.int8), 1108, axis=1)
            group_plate_probs[idx,j] = np.array(pp_mult)[mask].sum()/len(pp_mult)
    exp_to_group = group_plate_probs.argmax(1) # test group assignments
    
    # Mask out the empty groups
    def _select_plate_group(pp_mult, idx):
        # Create a mask to zero out values
        sub_test = df.loc[df.expt == all_test_exp[idx],:]
        assert len(pp_mult) == len(sub_test)
        mask = np.repeat(plate_groups[np.newaxis, :, exp_to_group[idx]], len(pp_mult), axis=0) != \
               np.repeat(sub_test.tray.values[:, np.newaxis].astype(np.int8), 1108, axis=1)
        pp_mult[mask] = 0
        return pp_mult
    
    probsleak = df.iloc[:,:1108].values
    for t, idx in enumerate(range(len(all_test_exp))):
        indices = (df.expt == all_test_exp[idx])    
        preds = probsleak[indices,:1108].copy()    
        probsleak[indices,:1108] = _select_plate_group(preds, idx)
    df.iloc[:,:1108] = probsleak

    
    #loop through each id_code and find balanced labels
    predslist = []   #list for final prediction
    idcodes = []    #idcodes
    for expt in unique_expt[:1]:
        dfunique = df[df['expt']==expt]   #new df for specific expt
        logits = dfunique.to_numpy()           #convert to np array
        idcodes.extend(dfunique['id_code'].tolist())
        logits = logits[:,:1108]                    #only select logits
        logits = logits.astype('float32')              
        y = torch.from_numpy(logits)#.cuda()           #convert to torch tensor
        alpha = args.start_alpha
        print("Starting id_code {}".format(expt))
        #coefs = torch.ones(y.shape[1]).cuda().float()
        coefs = torch.ones(y.shape[1]).float()
        last_score = _compute_score_with_coefficients(y, coefs)
        print("Start score", last_score)
        while alpha >= args.min_alpha:
            coefs = _find_best_coefficients(y, coefs, iterations=3000, alpha=alpha)
            new_score = _compute_score_with_coefficients(y, coefs)

            if new_score <= last_score:
                alpha *= 0.9

            last_score = new_score

            predicts = _get_predicts(y, coefs)   #new final preds in torch format
            predicts = predicts.cpu()
            np_predicts = predicts.numpy()
            np_predicts_argmax = np.argmax(np_predicts, axis=1)
            cv = (dfunique['sirna'] == np_predicts_argmax).mean()
            print("Score: {}, alpha: {}, cv: {:.4f}".format(last_score, alpha, cv))
            
        predslist.extend(np_predicts_argmax)

    #save submission
    df_submit = pd.DataFrame({'id_code': idcodes, 'sirna': predslist})
    df_submit.to_csv(args.output_path, index=False)

if __name__ == "__main__":
    main()

'''
Start score 77.70762634277344
100%|██████████| 3000/3000 [00:26<00:00, 115.01it/s]
  0%|          | 12/3000 [00:00<00:26, 111.56it/s]Score: 81.31773376464844, alpha: 0.01, cv: 0.7572
100%|██████████| 3000/3000 [00:26<00:00, 113.69it/s]
  0%|          | 11/3000 [00:00<00:27, 108.68it/s]Score: 83.664306640625, alpha: 0.01, cv: 0.7735
100%|██████████| 3000/3000 [00:26<00:00, 113.50it/s]
  0%|          | 11/3000 [00:00<00:29, 101.80it/s]Score: 85.46936798095703, alpha: 0.01, cv: 0.7843
100%|██████████| 3000/3000 [00:26<00:00, 113.19it/s]
  0%|          | 13/3000 [00:00<00:24, 122.77it/s]Score: 87.54518127441406, alpha: 0.01, cv: 0.7978
100%|██████████| 3000/3000 [00:25<00:00, 117.63it/s]
  0%|          | 12/3000 [00:00<00:26, 113.91it/s]Score: 89.25997924804688, alpha: 0.01, cv: 0.8087
100%|██████████| 3000/3000 [00:25<00:00, 116.72it/s]
  0%|          | 13/3000 [00:00<00:24, 123.18it/s]Score: 90.43325805664062, alpha: 0.01, cv: 0.8168
100%|██████████| 3000/3000 [00:25<00:00, 115.63it/s]
  0%|          | 11/3000 [00:00<00:27, 109.70it/s]Score: 91.4260482788086, alpha: 0.01, cv: 0.8267
100%|██████████| 3000/3000 [00:26<00:00, 111.36it/s]
  0%|          | 13/3000 [00:00<00:24, 122.37it/s]Score: 92.50907135009766, alpha: 0.01, cv: 0.8330
100%|██████████| 3000/3000 [00:26<00:00, 111.85it/s]
  0%|          | 12/3000 [00:00<00:26, 113.03it/s]Score: 92.96033477783203, alpha: 0.01, cv: 0.8330
100%|██████████| 3000/3000 [00:26<00:00, 111.24it/s]
  0%|          | 12/3000 [00:00<00:24, 119.85it/s]Score: 93.50184631347656, alpha: 0.01, cv: 0.8384
100%|██████████| 3000/3000 [00:26<00:00, 113.36it/s]
  0%|          | 11/3000 [00:00<00:28, 105.70it/s]Score: 93.86286926269531, alpha: 0.01, cv: 0.8366
100%|██████████| 3000/3000 [00:25<00:00, 115.87it/s]
  0%|          | 12/3000 [00:00<00:25, 115.47it/s]Score: 94.49462890625, alpha: 0.01, cv: 0.8384
100%|██████████| 3000/3000 [00:26<00:00, 115.17it/s]
  0%|          | 12/3000 [00:00<00:26, 114.32it/s]Score: 95.48741149902344, alpha: 0.01, cv: 0.8466
100%|██████████| 3000/3000 [00:26<00:00, 112.34it/s]
  0%|          | 11/3000 [00:00<00:28, 106.43it/s]Score: 95.84841918945312, alpha: 0.01, cv: 0.8475
100%|██████████| 3000/3000 [00:27<00:00, 110.01it/s]
  0%|          | 12/3000 [00:00<00:25, 117.20it/s]Score: 96.2996826171875, alpha: 0.01, cv: 0.8556
100%|██████████| 3000/3000 [00:26<00:00, 115.15it/s]
  0%|          | 12/3000 [00:00<00:25, 119.27it/s]Score: 96.84120178222656, alpha: 0.01, cv: 0.8556
100%|██████████| 3000/3000 [00:25<00:00, 115.93it/s]
  0%|          | 12/3000 [00:00<00:25, 116.14it/s]Score: 97.65347290039062, alpha: 0.01, cv: 0.8637
100%|██████████| 3000/3000 [00:26<00:00, 114.65it/s]
  0%|          | 11/3000 [00:00<00:27, 107.90it/s]Score: 97.833984375, alpha: 0.01, cv: 0.8691
100%|██████████| 3000/3000 [00:25<00:00, 116.11it/s]
  0%|          | 11/3000 [00:00<00:27, 109.49it/s]Score: 97.92424011230469, alpha: 0.01, cv: 0.8709
100%|██████████| 3000/3000 [00:25<00:00, 116.84it/s]
  0%|          | 12/3000 [00:00<00:26, 112.68it/s]Score: 97.92424011230469, alpha: 0.005, cv: 0.8709
100%|██████████| 3000/3000 [00:25<00:00, 117.58it/s]
  0%|          | 12/3000 [00:00<00:25, 118.91it/s]Score: 97.92424011230469, alpha: 0.0025, cv: 0.8709
100%|██████████| 3000/3000 [00:26<00:00, 114.29it/s]
  0%|          | 12/3000 [00:00<00:26, 112.11it/s]Score: 97.92424011230469, alpha: 0.00125, cv: 0.8709
100%|██████████| 3000/3000 [00:25<00:00, 117.27it/s]
  0%|          | 13/3000 [00:00<00:24, 121.83it/s]Score: 97.92424011230469, alpha: 0.000625, cv: 0.8709
100%|██████████| 3000/3000 [00:25<00:00, 117.34it/s]
  0%|          | 12/3000 [00:00<00:25, 117.61it/s]Score: 97.92424011230469, alpha: 0.0003125, cv: 0.8709
100%|██████████| 3000/3000 [00:25<00:00, 117.30it/s]
  0%|          | 12/3000 [00:00<00:26, 114.48it/s]Score: 97.92424011230469, alpha: 0.00015625, cv: 0.8709
100%|██████████| 3000/3000 [00:25<00:00, 117.58it/s]Score: 97.92424011230469, alpha: 7.8125e-05, cv: 0.8709
'''